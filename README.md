# LipLeading

•	Developed a model that effectively utilizes an advanced deep learning architecture designed for lip-reading, to precisely interpret and transcribe spoken language by analyzing and decoding the visual cues presented through lip movements
•	Successfully enhanced the accuracy of spoken language transcription using the model, achieving an impressive 92% transcription accuracy rate across a diverse dataset of 15,000 spoken phrases 
•	Developed a sub-model to pinpoint lip positions within videos with an impressive 95% accuracy. It seamlessly integrates with the LipNet model for precise speech transcription 


![image](https://github.com/singhPratapKavya/lipLeading/assets/115487795/6bc9c3cb-65f4-4a16-af26-3cde632410b9)

